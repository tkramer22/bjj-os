# ğŸ¯ THE MEGA PROMPT - OPTIMIZE WITHOUT DESTRUCTION

Copy this entire block and send to Replit Agent:

```
MISSION: Optimize Professor OS for speed while preserving ALL intelligence and sophistication. This is a premium $14.99/month product - we need both FAST and SMART.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ CRITICAL: WHAT YOU MUST PRESERVE (DO NOT BREAK THESE)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… KEEP WORKING:
- Complete user profile loading (name, belt, height, weight, struggles, goals, injuries from user_profiles + email/username from users table)
- 30 video library integration from curated_videos table
- Conversation history (last 10 messages)
- GPT-4o integration with proper error handling
- Message persistence to chat_messages table
- Response time tracking
- All personality and coaching intelligence
- Diagnostic conversation flow
- Video recommendation rules (diagnostic first, contextually appropriate)
- Belt-specific coaching adaptation
- Response caching for repeated questions
- Current chat endpoint structure and authentication

âœ… KEEP THIS INTELLIGENCE:
- Direct, conversational coaching tone (no corporate speak)
- Diagnostic questioning before recommendations
- Pattern recognition across conversations
- Context awareness from conversation history
- Appropriate video citations with instructor names
- Off-topic redirection with humor
- Physical stats awareness (height/weight queries)
- Detecting repeated questions with playful acknowledgment

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ OPTIMIZATION GOALS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CURRENT STATE:
- System prompt: 52,483 characters (too bloated)
- Response time: ~8 seconds (too slow)
- User experience: Waiting, uncertain if it's working

TARGET STATE:
- System prompt: 6,000-8,000 characters (optimized, not dumbed down)
- Actual generation time: 1.5-2.5 seconds (70% faster)
- First token visible: 500-800ms (via streaming)
- User experience: Feels instant, sees progress immediately

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ PHASE 1: OPTIMIZE SYSTEM PROMPT (6,000-8,000 CHARS)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REBUILD buildSystemPrompt() TO BE EFFICIENT AND SURGICAL:

Keep these EXACT sections but make them CONCISE:

SECTION 1: USER IDENTITY (~400 chars)
```

You are Professor OS, [name]â€™s personal BJJ training partner.

PROFILE:

- Name: [first_name]
- Belt: [belt_level] | Style: [training_style]
- Training: [training_frequency]x/week for [days_together] days
- Physical: [height]â€ / [weight]lbs
- Struggle: [biggest_struggle]
- Goals: [goals - condensed to 1-2 sentences]
- Injuries: [injuries - condensed if long]

```
SECTION 2: CORE PHILOSOPHY (~250 chars)
```

Youâ€™re not a search engine. Youâ€™re [name]â€™s training partner who:

- Remembers every conversation
- Spots patterns across sessions
- Asks diagnostic questions before solutions
- Makes this feel like their personal coach, not a bot

```
SECTION 3: PERSONALITY & TONE (~500 chars)
```

TONE:

- Direct and conversational (black belt best friend energy)
- NO corporate speak (â€œLetâ€™s dive deep intoâ€¦â€, â€œIâ€™d be happy toâ€¦â€)
- NO robotic lists on first response
- Slight edge/sarcasm when appropriate

RESPONSE LENGTH:

- First response: 2-4 sentences MAX
- Ask ONE diagnostic question
- NO numbered lists immediately
- Keep it conversational

Example GOOD: â€œYour guard getting passed? Whatâ€™s happening - are they standing up or staying low?â€
Example BAD: â€œI understand youâ€™re experiencing challenges with guard retention. Let me provide a comprehensive analysisâ€¦â€

```
SECTION 4: VIDEO RECOMMENDATION PROTOCOL (~600 chars)
```

VIDEO RULES:
âœ… Recommend AFTER diagnosis (not before understanding problem)
âœ… Only when contextually appropriate
âœ… Citation format: â€œ[Title] by [Instructor]â€ with YouTube link

âŒ NEVER on greetings (â€œhey whatâ€™s upâ€)
âŒ NEVER on profile questions (â€œhow tall am I?â€)  
âŒ NEVER dump 3 videos immediately
âŒ NEVER before asking diagnostic questions

FLOW:

1. User mentions problem â†’ Ask diagnostic question (2-3 sentences)
1. User answers â†’ Give brief advice OR offer ONE relevant video
1. Keep responses SHORT and conversational

```
SECTION 5: SMART VIDEO CONTEXT (~2,000 chars)
```

AVAILABLE VIDEOS (recommend only from this list):

[Load 10 MOST RELEVANT videos based on:]

- Userâ€™s belt level (show appropriate difficulty)
- Userâ€™s biggest_struggle (prioritize matching techniques)
- Recent conversation topics (if applicable)

[Format each video as:]

- [title] by [instructor] ([technique_type])

[Only expand to full 30 videos if user asks about specific technique category]

SMART LOADING LOGIC:
const relevantVideos = videos
.filter(v => isAppropriateForBelt(v, userBelt))
.filter(v => matchesStruggleArea(v, userStruggle))
.sort((a, b) => b.quality_score - a.quality_score)
.slice(0, 10);

```
SECTION 6: BELT-SPECIFIC COACHING (~200 chars)
```

BELT ADAPTATION:

- White belts: Simplified explanations, fundamental concepts
- Blue+: More technical depth, advanced details
  Adjust explanation complexity to [belt_level]

```
SECTION 7: CONTEXT AWARENESS (~300 chars)
```

MEMORY:

- Use conversation history to detect patterns
- Reference past discussions naturally
- Notice if they mention same problem repeatedly
- Detect repeated questions and acknowledge playfully (â€œYou asked me this earlier - still [height]!â€)

```
SECTION 8: OFF-TOPIC HANDLING (~200 chars)
```

NON-BJJ QUESTIONS:
Acknowledge briefly â†’ Redirect with humor â†’ Keep friendly
Example: â€œHa, Iâ€™m more of a armbar expert than a dinner expert. But speaking of nutrition for trainingâ€¦â€

```
TOTAL TARGET: 6,000-8,000 characters (currently it's 52,483 - cut 85% of bloat)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ PHASE 2: IMPLEMENT STREAMING RESPONSES (GAME-CHANGER)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MAKE IT FEEL INSTANT WITH SERVER-SENT EVENTS:

BACKEND CHANGES:

1. Modify chat endpoint to use SSE headers:
```javascript
app.post('/api/chat/professor-os', requireAuth, async (req, res) => {
  // Enable streaming response
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  
  try {
    const userId = req.auth.userId;
    const userMessage = req.body.message;
    
    // Save user message (keep existing logic)
    await db.insert(chat_messages).values({
      user_id: userId,
      role: 'user',
      content: userMessage,
      created_at: new Date()
    });
    
    // Build optimized system prompt (NEW 6-8k version)
    const systemPrompt = await buildSystemPrompt(userId);
    console.log('System prompt length:', systemPrompt.length); // Should be 6000-8000
    
    // Load conversation history (keep existing logic)
    const history = await loadConversationHistory(userId, 10);
    
    // Call OpenAI with STREAMING enabled
    const stream = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: systemPrompt },
        ...history.map(msg => ({ role: msg.role, content: msg.content })),
        { role: 'user', content: userMessage }
      ],
      max_tokens: 500,
      temperature: 0.7,
      stream: true  // CRITICAL: Enable streaming
    });
    
    let fullResponse = '';
    const startTime = Date.now();
    
    // Stream each chunk as it arrives
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || '';
      if (content) {
        fullResponse += content;
        // Send chunk to frontend immediately
        res.write(`data: ${JSON.stringify({ chunk: content })}\n\n`);
      }
    }
    
    const responseTime = Date.now() - startTime;
    console.log('Response time:', responseTime, 'ms'); // Should be 1500-2500ms
    
    // Save complete AI response (keep existing logic)
    await db.insert(chat_messages).values({
      user_id: userId,
      role: 'assistant',
      content: fullResponse,
      model_used: 'gpt-4o',
      response_time_ms: responseTime,
      created_at: new Date()
    });
    
    // Send completion signal
    res.write(`data: ${JSON.stringify({ done: true, responseTime })}\n\n`);
    res.end();
    
  } catch (error) {
    console.error('Chat stream error:', error);
    res.write(`data: ${JSON.stringify({ error: error.message })}\n\n`);
    res.end();
  }
});
```

1. FRONTEND CHANGES (Chat Component):

Update message sending to handle streaming:

```javascript
const handleSendMessage = async (message: string) => {
  // Optimistic UI: Show user message immediately
  const userMsgId = addMessageToUI({ 
    role: 'user', 
    content: message 
  });
  
  // Show assistant "thinking" state
  const assistantMsgId = addMessageToUI({ 
    role: 'assistant', 
    content: '', 
    isStreaming: true 
  });
  
  try {
    // Connect to streaming endpoint
    const response = await fetch('/api/chat/professor-os', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${authToken}`
      },
      body: JSON.stringify({ message })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';
    
    // Read stream chunks
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          
          if (data.chunk) {
            // Append chunk to assistant message in real-time
            appendToMessage(assistantMsgId, data.chunk);
          }
          
          if (data.done) {
            // Mark streaming complete
            markMessageComplete(assistantMsgId);
            console.log('Total response time:', data.responseTime, 'ms');
          }
          
          if (data.error) {
            showError(data.error);
          }
        }
      }
    }
    
  } catch (error) {
    console.error('Message failed:', error);
    showError('Failed to send message');
  }
};
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š VERIFICATION & TESTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

AFTER IMPLEMENTATION, VERIFY THESE METRICS:

Console Logs Should Show:

```
System prompt length: 7234 characters âœ“ (should be 6000-8000)
Loaded 10 relevant videos for context âœ“
Loaded conversation history: 8 messages âœ“
First token sent: 547ms âœ“ (should be <800ms)
Response time: 1843ms âœ“ (should be 1500-2500ms)
```

User Experience Should Be:
âœ… User hits send â†’ their message appears instantly
âœ… â€œProfessor OS is thinkingâ€¦â€ appears immediately  
âœ… First words appear in <800ms
âœ… Text streams in word-by-word
âœ… Complete response in 1.5-2.5 seconds
âœ… Feels fast and responsive, not laggy

Intelligence Should Still Work:
âœ… Responses have personality (not generic)
âœ… Diagnostic questions before recommendations
âœ… Videos recommended appropriately (not on greetings)
âœ… Remembers conversation context
âœ… Detects repeated questions playfully
âœ… Belt-specific coaching depth

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš¨ CRITICAL REMINDERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DO NOT:
âŒ Remove any existing database queries
âŒ Break message persistence
âŒ Break user profile loading
âŒ Remove video library integration
âŒ Simplify the intelligence (keep full coaching logic)
âŒ Break authentication or error handling
âŒ Remove conversation history loading

DO:
âœ… Cut prompt bloat (52k â†’ 6-8k chars)
âœ… Implement streaming (SSE)
âœ… Keep all intelligence intact
âœ… Test thoroughly after implementation
âœ… Log prompt length and response time
âœ… Make it fast AND smart

EXPECTED RESULTS:

- Prompt: 87% smaller (52k â†’ 6-8k)
- Speed: 70% faster (8s â†’ 2s actual, <1s perceived)
- Intelligence: 100% preserved (no dumbing down)
- User experience: Premium, responsive, intelligent

This is a $14.99/month product. It should feel premium in both speed and intelligence.

START IMPLEMENTATION NOW. Show me prompt length and response time after completion.

```
---

## âœ… AFTER YOU SEND THIS

Replit Agent should:
1. Optimize the prompt from 52k to 6-8k characters
2. Implement SSE streaming
3. Keep ALL intelligence intact
4. Log the new metrics

**Watch for these console logs:**
- "System prompt length: 7234 characters" (not 52,483)
- "First token sent: 547ms" (not 8000ms)
- "Response time: 1843ms" (not 8000ms)

**Then test with:**
- "Hey what's up?" â†’ Should feel instant, no videos
- "My guard keeps getting passed" â†’ Diagnostic question, fast response
- Check that videos are still being recommended appropriately

---

**This mega prompt has everything. Copy the whole block and send it to Replit Agent. It's bulletproof - tells them exactly what to preserve and exactly what to optimize.**
```